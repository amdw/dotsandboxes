\documentclass[a4paper,twocolumn]{article}

\usepackage{palatino}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{color}
\usepackage{calc}
\usepackage{wasysym}

\DeclareMathOperator{\mex}{mex}
\newcommand{\loony}{\rightmoon}
\newcommand{\cgtgame}[2]{\{#1 \:|\: #2\}}

\newtheorem{thm}{Theorem}[section]
\newtheorem{sstealing}[thm]{Theorem}
\newtheorem{addcoins}[thm]{Lemma}
\newtheorem{freecoins}[thm]{Theorem}
\newtheorem{halfheartedbad}[thm]{Theorem}
\newtheorem{opensmallest}[thm]{Theorem}
\newtheorem{gamelength}[thm]{Theorem}
\newtheorem{dnbgamelength}[thm]{Corollary}
\newtheorem{parityruleofthumb}[thm]{Rule}
\newtheorem{dnbparityruleofthumb}[thm]{Rule}

\begin{document}

\title{The Dots-and-Boxes Game}
\author{Andrew Medworth (\texttt{https://github.com/amdw})}
\date{\today}
\maketitle

\begin{abstract}
  An introduction to the game dots-and-boxes, and to the more general
  game strings-and-coins. Aims to explain why these games are
  interesting, and to discuss some principles of strategy. Intended
  for readers with some mathematical background: anyone unfamiliar
  with techniques such as proof by induction will probably find this
  paper difficult, and may prefer to learn the game from another
  source instead.
\end{abstract}

\tableofcontents

\section{Introduction}

\subsection{The rules of dots-and-boxes}

Dots-and-boxes is a game for two players.

\begin{enumerate}
  \item The game is played on a rectangular grid of dots.
  \item A move consists of drawing a line of the player's choice
    connecting a pair of horizontally or vertically adjacent dots.
  \item It is possible for a player's move to complete either one or
    two $1 \times 1$ boxes. When this happens, the player scores one
    point for each completed box (normally recorded by writing her
    initial inside each one) and \emph{must} make another move: a
    player's turn comes to an end when she makes a move which does not
    complete any boxes.
  \item The game ends when all boxes have been completed; the winner
    is the player who has completed more boxes.
\end{enumerate}

An example game is shown in Figure \ref{sampledab}; each move played
is shown in bold, with the letter under each position showing the
player making that move.

\begin{figure*}
  \centering
  \def\svgscale{0.7}
  \input{fig_sampledab.pdf_tex}
  \caption{Sample dots-and-boxes game, which player $A$ wins 3--1}
  \label{sampledab}
\end{figure*}

The rules of dots-and-boxes are very simple: the game can be learned
in moments, and it can be played purely with pencil and paper. The
size of the board can be varied to alter the simplicity and length of
the game: the board with $5 \times 5$ boxes is already quite deep. The
strategy of the game is complex and interesting, and the aim of this
paper is to explore it in more detail.

\subsection{Strings-and-coins}

Dots-and-boxes is a special case of a more general game called
\emph{strings-and-coins}.

\begin{enumerate}
  \item This game begins with a set of \emph{coins}, and a set of
    \emph{strings} each connecting a pair of coins; some coins may
    also have one or more strings connecting them to the
    \emph{ground}.
  \item A move consists of removing a string of the player's choice.
  \item It is possible for a player's move to remove the last string
    connected to either one or two coins. When this happens, the
    player wins those coins, removing them from the game, and
    \emph{must} play another move, her turn ending when she removes a
    string which does not win any coins.
  \item The game ends when all coins are gone; the winner is the
    player who has won more coins.
\end{enumerate}

The strings-and-coins game parallel to the dots-and-boxes game in
Figure \ref{sampledab} is shown in Figure \ref{samplesnc}. Connections
to the ground are indicated by arrows. In each position, the moves
played are shown in bold. Underneath is the player making the move
shown, along with the score following that move.

\begin{figure*}
  \centering
  \def\svgscale{0.7}
  \input{fig_samplesnc.pdf_tex}
  \caption{Sample strings-and-coins game equivalent to Figure \ref{sampledab}}
  \label{samplesnc}
\end{figure*}

For those familiar with mathematical graph theory, a strings-and-coins
position forms a \emph{multigraph}, with the vertices being the coins
and the edges being the strings. The ground can be thought of as a
special vertex which cannot be captured. (A position is a multigraph
rather than an ordinary graph because a coin can have more than one
string connecting it to the ground, or indeed another coin.)

The $m \times n$ game of dots-and-boxes is the special case of
strings-and-coins where $mn$ coins are connected in a rectangular $m
\times n$ grid, with the outer coins connected to the ground (the four
corner coins having two ground links each, and the other edge coins
having one ground link each).

Strings-and-coins is a more general game than dots-and-boxes, because
in strings-and-coins it is possible to start with a position of any
shape and connectivity whatsoever, whereas in dots-and-boxes, the
``coins'' are fixed in a rectangular grid, and all strings have length
1 and are either vertical or horizontal. For example, in
strings-and-coins it is possible to have a loop of three coins,
whereas this is not possible in dots-and-boxes.

Anything we learn about strings-and-coins will also apply to
dots-and-boxes; we will therefore mostly focus our attention on
strings-and-coins, occasionally making reference to dots-and-boxes
where something we learn has specific implications there.

\section{Basic terminology}

Where possible, I have tried to be consistent with the standard
terminology of graph theory, and with existing literature such as
\cite{berl}.

We will call the two players $A$ and $B$, with $A$ generally moving
first in a given position.

The \emph{valency} or \emph{degree} of a coin is the number of strings
connected to it (these terms are borrowed from graph theory). In the
starting position of dots-and-boxes, all coins have valency 4; each
move reduces the valency of either one or two coins by 1. A coin of
valency 1 can be immediately captured.

A \emph{joint} is a coin of degree 3 or more.

A \emph{loop} is a connected set of coins which all have valency 2, and
form a circuit. An $n$-loop is a loop consisting of $n$ coins. (In
dots-and-boxes, there are no loops with fewer than 4 coins, and due to
the symmetry, all loops have an even number of coins.)

A \emph{(closed) chain} is a connected set of coins with valency 2
which is not a loop. A chain has two ends, which can either be
connected to the ground or to a joint. An \emph{open chain} is one
which can be immediately captured, i.e.\ a chain where one or both ends
has valency 1. A $n$-chain is a chain consisting of $n$ coins.

A chain is \emph{independent} if it is connected to the ground (rather
than a joint) at both ends.

The act of \emph{opening} a chain or loop is cutting it so that it
becomes an open chain, which can then be captured.

A \emph{double-cross move} is a move which wins two coins at once
(because the string removed connected two coins of valency 1). These
moves are of strategic importance for reasons we will see later.

Let $V(P)$ be the net value of a position $P$, assuming optimal play
from both sides, from the perspective of the player who has to play
first in it. Clearly $V(P)$ will be an integer, and could be either
positive, zero or negative, depending on whether $P$ is advantageous
for the first player. $V(P)$ is also known as the \emph{minimax} value
of $P$ and $V$ is the \emph{value function} of strings-and-coins.

\section{Endgame fundamentals}

\subsection{Control and loony moves}

To understand the strategy of a game, it is often a good idea to begin
with positions close to the end of the game, since the understanding
of earlier positions depends on later ones.

Let us consider a very simple endgame position $S_n$ consisting of a
single closed $n$-chain. Obviously $V(S_n)=-n$, as there is no
alternative but to open the chain for the opponent, who will take all
$n$ coins straight away.

Now consider the position $D_n$ with $2n$ coins divided into
\emph{two} closed $n$-chains. At first glance it might appear that
this position is a $n$--$n$ draw, as $A$ must open one chain for $B$,
who will take it and then be forced to open the other one for
$A$. However this is not true: when $A$ opens the first chain, $B$ can
take all but the last two boxes, and then sacrifice them with a
\emph{double-dealing move} as shown in Figure \ref{dddemo} (with
$n=5$). Because this move does not win a coin, it ends $B$'s turn, and
forces $A$ to make a move. $A$ might as well take the two sacrificed
coins, because in either case, he is also forced to open the remaining
chain for $B$, which $B$ then wins. Thus $B$ wins by $2n - 2$ points
to 2, so $V(D_n) = 4-2n$.

\begin{figure}
  \centering
  \def\svgscale{0.7}
  \input{fig_doubledeal.pdf_tex}
  \caption{Maintaining control through double-dealing}
  \label{dddemo}
\end{figure}

Notice that this only works with $n \ge 3$: a closed chain of length 2
can be opened by removing the middle string, in which case a
double-dealing move is impossible. Only when $n \ge 3$ is there no way
to open a closed $n$-chain without allowing a double-dealing move.

A similar situation arises with loops, but with one important
difference: when a loop is opened, in order to play a double-dealing
move a player must sacrifice 4 boxes, rather than 2, as shown in
Figure \ref{loopdoubledeal}. This is because an opened loop has no
link to the ground, so the only way to avoid taking a coin at the end
(and thus be forced to continue making moves) is to take the string
between two connected pairs of coins, sacrificing both pairs. This
means that a double-dealing move is only possible with an $n$-loop if
$n \ge 4$.

\begin{figure}
  \centering
  \def\svgscale{0.7}
  \input{fig_loopdoubledeal.pdf_tex}
  \caption{Double-dealing on a loop}
  \label{loopdoubledeal}
\end{figure}

Double-dealing moves are an absolutely central concept in
strings-and-coins strategy, because they allow a player to maintain
\emph{control} of a position, to decide whether to play first in the
rest of the position or to force the opponent to do so.

Because of this, a \emph{long chain} is defined as a chain of at least
\emph{three} coins, and a \emph{long loop} is defined as a loop of at
least \emph{four} coins. A long chain or loop is one which cannot be
opened without allowing a double-dealing move. By contrast a
\emph{short} chain or loop is one which is not long.

(I do not particularly like this terminology, because the words
``long'' and ``short'' are such common words, and giving them a
specific technical meaning like this can often be confusing. However
they are standard in the dots-and-boxes literature, so throughout this
paper I have tried to consistently use ``long'' and ``short'' in this
technical sense, preferring ``large'' and ``small'' in more informal
contexts.)

If there are more than two $n$-chains, notice that player $B$ can
maintain control all the way to the end of the game, by taking all but
two coins of each chain and then playing a double-dealing move,
forcing $A$ to open the next chain at the cost of two coins, and
repeating this for each chain except the last, which he can capture in
its entirety. This strategy will certainly win the game if $n>3$; if
$n=3$ then the situation is slightly more complex, because sacrificing
two coins from a 3-chain results in a net loss of one coin. A similar
observation holds true for loops which are sufficiently large to allow
a double-dealing move without net loss. We will explore this topic in
more detail in section \ref{smallchains}.

A \emph{loony move} is defined as a move which allows the opponent to
play a double-dealing move. There are four types of loony move:

\begin{enumerate}
  \item Opening a long chain
  \item Opening a long loop
  \item Opening a 2-chain by cutting the link at one of the ends:
    this is called a \emph{half-hearted handout}, in contrast to a
    \emph{hard-hearted handout} which is opening the 2-chain by
    cutting the middle link (and is not a loony move).
  \item Handing one of these situations back to the opponent by
    playing in an unrelated area of the board when the opponent has
    made a loony move of their own.
\end{enumerate}

When a player makes a loony move, it hands over control of the
position to the opponent, and so if a player can force her opponent to
make a loony move, she is almost always winning. (We will discuss the
exceptions shortly.)

A \emph{loony endgame} is defined as a strings-and-coins position in
which the only possible moves are loony moves. A \emph{loony position}
is defined as one in which a loony move has just been made.

These central concepts of strings-and-coins strategy bring us to our
first theorem.

\begin{sstealing}\label{sstealing}
  If a player has just made a loony move, her opponent can always
  score at least half of the remaining points: in other words, for any
  loony position $L$, $V(L) \ge 0$.
\end{sstealing}

\begin{proof}
  Let $P$ be the position with the coins offered by the loony move
  removed.

  The proof uses a technique called \emph{strategy-stealing}. It
  relies on the fact that from $L$, the player to move can choose
  whether to take all the coins on offer and play first in $P$, or
  play a double-dealing move, sacrificing a few coins but forcing the
  opponent to play first in $P$.

  Let $s$ be the minimum number of coins the player would have to
  sacrifice in order to play a double-dealing move, and let $m$ be the
  total number of coins placed on offer by the loony move. Note that
  $s$ is either 2 or 4, depending on whether a chain or a loop has
  been opened, and $m \ge s$.

  By taking all the coins and playing first in $P$, the player's
  outcome would be $m + V(P)$. By taking all but $s$ coins and forcing
  the opponent to play first in $P$, the player's outcome would be
  $m-2s-V(P)$. So $$V(L) = \max(m+V(P), m-2s-V(P))$$

  If $V(P) \ge -m$ then $V(L) \ge 0$ straight away, so suppose $V(P) <
  -m$. Then $m-V(P) > 2m$, and thus as $m \ge s$, $$m-2s-V(P) > 2m-2s
  \ge 0$$ so in this case $V(L) \ge 0$ also.
\end{proof}

Notice that this is a non-constructive proof, which does not tell us
which of the two options (taking all the coins or making a
double-dealing move) is the correct one. The position $P$ might be
very complex, and it could be difficult to work out whether it is more
favourable to play first or second in it. The strategy-stealing
argument simply shows that since the first player has a free choice
between these two options, and one of them must win, a loony position
must be a win for the first player.

This shows that it is \emph{generally} undesirable to make a loony
move; that is not always the case, though, as sometimes the
alternatives are actually worse. We will see some examples in section
\ref{smallchains}.

However the third and fourth types of loony move can never be the sole
optimal move, and we will prove that now.

\begin{addcoins}\label{addcoins}
  For any position $P$, if $P'$ is the position resulting from adding
  $n$ capturable coins to $P$, then $V(P') \ge V(P)+n$.
\end{addcoins}
\begin{proof}
  This is immediate, as a gain of $V(P)+n$ coins can be made from $P'$
  by taking the $n$ available coins and then following the optimal
  strategy in $P$. (There may of course be a better strategy
  available.)
\end{proof}

\begin{freecoins}\label{freecoins}
  Any coins which can be captured without affecting the ability to
  play a double-dealing move later in the turn should always be
  captured immediately.
\end{freecoins}
\begin{proof}
  Let:
  \begin{itemize}
    \item $P$ be the current position
    \item $n$ be the maximum number of coins we can capture without
      affecting the ability to play a double-dealing move
    \item $P_t$ the position after we capture all possible coins from
      $P$ and then make the optimal move in the remaining position
    \item $P_d$ the position resulting from taking $n$ coins from $P$
      and then making a double-dealing move
  \end{itemize}

  If we take any number of coins $m < n$ and then play a
  double-dealing move, the resulting position is the same as $P_d$ but
  with $n-m$ extra capturable coins, so by lemma \ref{addcoins}, its
  value is at least $n-m$ greater than $V(P_d)$.

  Similarly, if we take any number of coins $m < n$, ignore the rest
  of the coins, and then play a non-double-dealing move, its value
  will be at least $n-m$ greater than $V(P_t)$.

  Thus, in either case, if we refrain from taking any other available
  coins, the opponent can take those coins and then play whatever
  optimal strategy they could have played if we had taken them. Thus
  we have achieved nothing except giving the opponent some free coins
  (and perhaps some other possibilities too, such as making a
  double-dealing move of their own.)
\end{proof}

\begin{halfheartedbad}\label{halfheartedbad}
  A half-hearted handout is never better than a hard-hearted handout.
\end{halfheartedbad}
\begin{proof}
  Let $P$ be the position without the two coins concerned.

  The value of the position after the hard-hearted handout is
  $2+V(P)$, as the two coins should always be captured by Theorem
  \ref{freecoins}.

  A half-hearted handout by $A$ gives $B$ the choice whether to take
  the two coins and play first in $P$, or to play a double-dealing
  move, which sacrifices two coins but forces $A$ to play first in
  $P$. So the value of the position after the half-hearted handout
  is $$\max(2+V(P),-2-V(P)) \ge 2+V(P)$$ by definition of $\max$.
\end{proof}

Results like this, which prove that a certain type of move can never
be worse than another type, are known as \emph{canonical play}
results. These are extremely useful, because they can significantly
simplify the calculations necessary to evaluate a position.

For example, Theorem \ref{halfheartedbad} means we never have to
consider half-hearted handouts, because we know they will never be
better than the equivalent hard-hearted handout. If the choice is
between a hard-hearted and a half-hearted handout, we can say the
former is the \emph{canonical move}.

Theorem \ref{freecoins} is even more powerful: it means that in many
situations where there are capturable coins, we do not need to
consider the possibility of not taking them. When a long chain or loop
is opened, taking all but the last few coins (two for a chain, four
for a loop) is \emph{canonical}, so we need only consider two
possibilities: taking the whole chain and the double-dealing move.

(It is important to realise that canonical play results only prove
that certain types of move cannot be the sole best move in the
position, and hence cannot affect the \emph{optimal} value of the
position. They say nothing about whether the position is winning or
losing. In some losing positions, a non-canonical move can give the
opponent more opportunities to go wrong, and so might be worth a try
in a practical game.)

Here is another useful canonical play result.

\begin{opensmallest}\label{opensmallest}
  For any two independent chains, or any two independent loops, of
  different sizes, it is never better to open the larger one than the
  smaller one.
\end{opensmallest}
\begin{proof}
  The proof uses a useful technique mentioned in \cite{berl} called
  \emph{the man in the middle}. This is a form of proof by
  contradiction.

  Suppose someone claims that, contrary to this theorem, opening the
  larger structure is better than opening the smaller one. We
  challenge this person to two simultaneous games, both starting from
  the same position. In Game 1, player $A$ is required to start by
  opening the smaller structure; in Game 2, player $A$ must start by
  opening the larger one. We take the role of player $A$ in Game 1,
  and our imaginary antagonist does the same in Game 2: she gets the
  position she prefers to play as $A$, and so do we.

  In order to prove she is right, our opponent will have to get a
  better result as player $A$ in Game 2 than we can achieve as player
  $A$ in Game 1: if she cannot, then her claim fails and the theorem
  is proven.

  The ``man in the middle'' technique shows that our challenger's task
  is indeed impossible, by taking the moves she plays in one game and
  playing equivalent moves against her in the other game, according to
  an equivalence we specify. The proof works by showing that
  regardless of the strategy our opponent chooses, we can
  \emph{always} find such equivalent moves, and that they will
  \emph{always} result in us doing at least as well in Game 1 as she
  does in Game 2. Our antagonist is essentially playing against
  herself, and we are the ``man in the middle'', hence the name.

  In this case, we see how our opponent responds to our opening of the
  smaller structure in Game 1, before choosing how to respond to her
  opening of the larger one in Game 2:

  \begin{itemize}
  \item If she takes the whole structure, we take the whole larger
    structure in Game 2, leaving us ahead.
  \item If she plays a double-dealing move, we play a double-dealing
    move ourselves on the opened structure in Game 2 (which we can
    always do, because the structure opened in Game 2 is larger). This
    again leaves us ahead, because the structures are either both
    chains or both loops, so the number of coins which must be
    sacrificed to double-deal is the same, and our structure is
    larger.
  \item If she opens the larger structure, we open the smaller
    structure in Game 2.
  \item If she plays elsewhere in the position, we copy her move in
    the other game.
  \end{itemize}

  We then await our opponent's response in Game 2, and make the
  equivalent move in Game 1, according to the same scheme: any move
  our opponent makes on the smaller structure in Game 2 we replicate
  on the larger structure in Game 1, and if she moves in the rest of
  the position, we simply copy her. We repeat this strategy until the
  both games are over.

  If $P$ is the position minus the two structures concerned, we will
  always achieve exactly the same score in $P$ in Game 1 as our
  opponent achieves in $P$ in Game 2, so any difference in outcomes
  will boil down to the two structures themselves.

  We may end up winning the larger structure in Game 1 or we may not;
  if we do, then we do better in Game 1 than our opponent in Game 2,
  because we win the larger structure and lose the smaller one in Game
  1, whereas our opponent wins the smaller one and loses the larger
  one in Game 2. (If our win of the larger structure is minus some
  coins sacrificed by a double-dealing move, so will be our opponent's
  win of the smaller structure in the other game.)

  However, even if we lose the larger structure in Game 1, we will win
  the smaller structure in Game 2, meaning both players win both
  structures in their respective games (possibly minus the same number
  of sacrificed coins), leaving the final outcomes the same.

  This shows that regardless of how good a strategy our opponent
  chooses in Game 2, we can always do \emph{at least} as well in Game
  1, possibly better, thus it \emph{cannot} be better to open the
  larger structure than the smaller one.

  (This proof depends on the fact that the two structures are
  independent of $P$, so no move played on them can affect our ability
  to copy our opponent in $P$. It also depends on the fact that any
  move played on a smaller structure can be copied on the larger one
  with no net loss of coins.)
\end{proof}

\subsection{Structure sizes and control}
\label{smallchains}

From the preceding discussion, it is clear that the concept of control
is extremely important to understanding a strings-and-coins
position. However, the winner in strings-and-coins is the player who
wins most coins, not the player who makes the last move or controls
the flow of the play. We now explore the relationship between these
two concepts.

First, suppose we have a position composed of an arbitrary
sub-position $S$ and a single chain with more coins than in all of
$S$. In this case, since the big chain contains more than half the
coins, the game will be won by whichever player can win it: neither
player will open the big chain unless they have no choice, so both
players will strive \emph{not} to take the last coin in $S$. In this
case control of $S$ will determine the outcome of the game.

In general, the more a position is dominated by chains and loops with
a large number of coins, the more important it is to have control,
because this will determine who is forced to give them away.

The complication comes from the fact that when a small enough chain
and or loop is opened, keeping control requires a net sacrifice of
coins, so if the position is dominated by such structures, naively
keeping control all the way to the end can result in defeat. It is in
these contexts that giving away control with a loony move can actually
be the optimal approach.

A chain or loop which does not require a net loss of coins to make a
double-dealing move is defined as \emph{very long}. Because making a
double-dealing move in a chain requires a sacrifice of two coins and
in a loop requires four coins, we now have the following
classification:

\begin{itemize}
  \item Chains of length 1 and 2 and loops of length 1, 2 or 3 are
    short (as they can always be opened with a non-loony move)
  \item Chains of length 3 and loops of length 4, 5, 6 or 7 are long
    but not very long (as they can only be opened with a loony move,
    but keeping control with a double-dealing move requires a net loss
    of coins)
  \item Larger chains and loops are both long and very long (these can
    only be opened with a loony move, after which control can be kept
    with no net loss).
\end{itemize}

(Again I register my objection to this terminology, but it is standard
and I will stick to it.)

We will now examine how smaller chains and loops affect
strings-and-coins positions.

\subsubsection{Long but not very long chains and loops}

Here we examine the effect of small long chains and loops by
considering a family of loony endgame positions $P_{i,k}$ consisting
of $i$ 3-chains and one $k$-chain, with $k \ge 3$. For example,
$P_{4,5}$ is shown in Figure \ref{p45}.

\begin{figure}
  \centering
  \def\svgscale{0.7}
  \input{fig_p45.pdf_tex}
  \caption{Position $P_{4,5}$}
  \label{p45}
\end{figure}

In $P_{i,k}$, $A$ can choose whether to open the $k$-chain or one of
the 3-chains, and in response, $B$ can choose whether to take the
whole chain or take all but two boxes and play a double-dealing move.

By Theorem \ref{opensmallest}, $A$ never does better to open the
$k$-chain than one of the 3-chains, so to compute $V(P_{i,k})$, we
need only consider opening a 3-chain, followed by either taking or
double-dealing in reply by $B$. Since removing one of the 3-chains
from $P_{i,k}$ yields $P_{i-1,k}$, we can calculate $V(P_{i,k})$
recursively as follows.

\begin{eqnarray*}
  V(P_{0,k}) & = & -k \\
  V(P_{i+1,k}) & = & \min(-3-V(P_{i,k}), 1+V(P_{i,k}))
\end{eqnarray*}

Example calculations for $k=3$, $k=4$ and $k=10$ can be seen in tables
\ref{vpik3}, \ref{vpik4} and \ref{vpik10}.

\begin{table*}[p]
  \centering
  \begin{tabular}{c c c c c c}
    $i$ & $V$ if $B$ takes & $V$ if $B$ double-deals & $V(P_{i,3})$ & $B$ taking optimal? & $B$ double-dealing optimal? \\
    \hline
    0 & -3 & -1 & -3 & Yes & No \\
    1 & 0 & -2 & -2 & No & Yes \\
    2 & -1 & -1 & -1 & Yes & Yes \\
    3 & -2 & 0 & -2 & Yes & No \\
    4 & -1 & -1 & -1 & Yes & Yes \\
    5 & -2 & 0 & -2 & Yes & No \\
    6 & -1 & -1 & -1 & Yes & Yes
  \end{tabular}
  \caption{$k=3$}
  \label{vpik3}
\end{table*}

\begin{table*}[p]
  \centering
  \begin{tabular}{c c c c c c}
    $i$ & $V$ if $B$ takes & $V$ if $B$ double-deals & $V(P_{i,4})$ & $B$ taking optimal? & $B$ double-dealing optimal? \\
    \hline
    0 & -4 & 0 & -4 & Yes & No \\
    1 & 1 & -3 & -3 & No & Yes \\
    2 & 0 & -2 & -2 & No & Yes \\
    3 & -1 & -1 & -1 & Yes & Yes \\
    4 & -2 & 0 & -2 & Yes & No \\
    5 & -1 & -1 & -1 & Yes & Yes \\
    6 & -2 & 0 & -2 & Yes & No \\
    7 & -1 & -1 & -1 & Yes & Yes \\
    8 & -2 & 0 & -2 & Yes & No
  \end{tabular}
  \caption{$k=4$}
  \label{vpik4}
\end{table*}

\begin{table*}[p]
  \centering
  \begin{tabular}{c c c c c c}
    $i$ & $V$ if $B$ takes & $V$ if $B$ double-deals & $V(P_{i,10})$ & $B$ taking optimal? & $B$ double-dealing optimal? \\
    \hline
    0 & -10 & 6 & -10 & Yes & No \\
    1 & 7 & -9 & -9 & No & Yes \\
    2 & 6 & -8 & -8 & No & Yes \\
    3 & 5 & -7 & -7 & No & Yes \\
    4 & 4 & -6 & -6 & No & Yes \\
    5 & 3 & -5 & -5 & No & Yes \\
    6 & 2 & -4 & -4 & No & Yes \\
    7 & 1 & -3 & -3 & No & Yes \\
    8 & 0 & -2 & -2 & No & Yes \\
    9 & -1 & -1 & -1 & Yes & Yes \\
    10 & -2 & 0 & -2 & Yes & No \\
    11 & -1 & -1 & -1 & Yes & Yes \\
    12 & -2 & 0 & -2 & Yes & No
  \end{tabular}
  \caption{$k=10$}
  \label{vpik10}
\end{table*}

We know from theorem \ref{sstealing} that no loony endgame can have a
positive value, but all the $V(P_{i,k})$ are strictly less than
zero. This is because the 3-chains have an odd number of coins, but
the number of coins you have to sacrifice to make a double-dealing
move is even, so the two never cancel out exactly.

(It is possible to construct a loony endgame position with value 0:
for example, the position consisting of two 4-loops shown in Figure
\ref{drawnloony}. In this case, taking the first loop would mean
sacrificing the second, while double-dealing the first loop would
sacrifice four coins to gain the second loop, with a draw in either
case.)

\begin{figure}
  \centering
  \def\svgscale{0.7}
  \input{fig_drawnloony.pdf_tex}
  \caption{A drawn loony endgame position}
  \label{drawnloony}
\end{figure}

Notice that the larger the value of $k$ (i.e.\ the bigger the big
chain), the longer double-dealing remains the optimal strategy for
$B$, the player in control. This is to be expected, as the bigger the
chain is, the more points it is worth sacrificing by double-dealing
from 3-chains to capture it.

However, in all cases, once $i$ is large enough (i.e.\ there are enough
3-chains), double-dealing after the opening of the first 3-chain
ceases to become the sole optimal strategy, and if there are an even
number of 3-chains, it ceases to become the optimal strategy at all.

The position consisting of four 3-chains, $P_{3,3}$, is a simple
counter-example to the notion that loony moves are always inferior to
non-loony moves. When $A$ opens the first 3-chain in this position,
$B$ does best to take it, winning 3 coins, and open the next 3-chain
for $A$, even though the latter is a loony move and a non-loony move
could have been played instead.

The reason is that giving away control by playing a loony move in the
position with three 3-chains, $P_{2,3}$, only loses one point, which
is more than offset by the three coins won in the process of reaching
that position. If instead $B$ had played a double-dealing move, he
would have been one point behind from the first chain, and only won
one point from $P_{2,3}$, so the game would have finished drawn.

$P_{3,3}$ is also a counter-example to the idea that the winner of a
strings-and-coins game is always the player who makes the last
move. If $A$ opens the first chain, $B$ takes it and opens the next
chain as discussed above, and $A$ double-deals (which is equally bad
for him as taking), $B$ will be leading 5--1 after the first two
chains are gone. As $B$ will have to open one of the last two chains
for $A$, $A$ will double-deal and then take the last chain, thus
winning the last two chains 4--2 and making the last move, but this
will result in a final score of 7--5 in $B$'s favour. So $A$ controls
whether he will make the last move of the game, by deciding whether to
take or double-deal on the second chain, but he is not able to win.

A very similar analysis would apply if the 3-chains from this example
were replaced by loops of length 4, 5, 6 or 7. All these structures
require a sacrifice of coins in order to retain control, so a precise
analysis of the rest of the position is required in order to know
whether double-dealing or taking is the right strategy. If the rest of
the position is close in score, it may be better to take all the coins
on offer and play a loony move, even though there was a non-loony move
available.

\subsubsection{Short chains and loops}

Recall that the defining characteristic of a short chain or loop is
that it can be opened with a non-loony move; therefore, sacrificing it
does not necessarily entail giving up control of the position.

From Theorems \ref{halfheartedbad} and \ref{opensmallest}, we know
that if we add a single short chain or loop of size $c$ to a loony
endgame $P$ resulting in a position $P'$, the best move will be to
open that short chain or loop (with a hard-hearted handout, if
applicable), sacrificing all the coins in it, but forcing our opponent
to play first in $P$, and thus $V(P') = -c-V(P)$.

If we continue to add short chains or loops to the position, the sign
of its value will flip back and forth, as the players will alternately
open one of the short structures, until one of them is forced to play
a loony move.

To see how this works with a concrete example, consider a family of
positions $S_{i,k}$ consisting of $i$ 2-chains plus one
$k$-chain. Then:

\begin{equation*}
  V(S_{i,k}) =
  \begin{cases}
    -k & \text{if } i = 0,\\
    -2-V(S_{i-1,k}) & \text{if } i > 0
  \end{cases}
\end{equation*}

For the case $k=3$, this means the value of the position alternates
between $-3$ (for even $i$) and $+1$ (for odd $i$), as either player
$A$ loses two coins on the last 2-chain but wins the final 3-chain, or
makes an even score on the 2-chains but has to give away the 3-chain.

For larger $k$, the oscillations as $i$ is increased are even larger,
as the significance of who wins the $k$-chain becomes greater. For
example $V(S_{i,10})$ is $-10$ for even $i$ and $+8$ for odd $i$.

\section{Middlegame fundamentals}

Having established some basic principles of endgame play, we now
consider how to aim towards a winning endgame while still in the
middlegame.

\subsection{How long is a game?}

While it is not true that the player who makes the last move
necessarily wins a game of strings-and-coins (or dots-and-boxes),
these situations are relatively rare exceptions, resulting from cases
where the position is dominated by smaller chains and loops. Most
games of dots-and-boxes have enough very long chains and loops that
the issue of control is decisive.

It is therefore important to consider whether there are any general
guidelines we can use to determine which player will make the last
move in a game, as that player will generally be able to win.

In this section, we will prove some results about how many turns there
are in a game of strings-and-coins or dots-and-boxes. Obviously, if
the total number of turns in the game is odd, the player who moves
first in the game will play last, whereas if this number is even, her
opponent will.

It turns out that the number of turns is affected by the number of
double-crossed moves made during the course of the game, in a way
which is perhaps slightly surprising. The following theorem shows
exactly how\footnote{I have never seen this theorem stated in quite
  this way in the dots-and-boxes literature, but I would be surprised
  if it is a new result.}.

\begin{gamelength}\label{gamelength}
  For any game of strings-and-coins starting from a position with $C$
  coins and $S$ strings, if $D$ double-crossed moves occur during
  the course of the game, then the total number of turns in the game
  is $$1 + S - C + D$$
\end{gamelength}
\begin{proof}
  This is rather laborious, so to avoid distracting readers who would
  rather skip it, I have put it in Appendix \ref{gamelengthproof}. (I
  would appreciate hearing from any reader who knows of a simpler
  proof of this result.)
\end{proof}

Applying this to dots-and-boxes gives the following elegant
corollary\footnote{This is the result given in most of the
  dots-and-boxes literature, including \cite{berl} and \cite{wways}.}.

\begin{dnbgamelength}\label{dnbgamelength}
  The number of turns in a game of dots-and-boxes in which $D$
  double-crossed moves occur is equal to the number of dots in the
  grid plus $D$.
\end{dnbgamelength}
\begin{proof}
  If a dots-and-boxes game is played on a grid of $m$ rows and $n$
  columns of boxes, the number of coins in the equivalent
  strings-and-coins position is $mn$. There are $m(n+1)$ horizontal
  strings and $n(m+1)$ vertical ones, so the total number of strings
  is $$2mn + m + n$$

  Substituting these into Theorem \ref{gamelength} and simplifying
  shows that the game will have $$(m+1)(n+1) + D$$ turns.  Since the
  board has $(m+1)(n+1)$ dots, we have our result.
\end{proof}

\subsection{Chain parity rules}

These results allow us, in many practical situations, to work out
quite a long way in advance which player is going to make the last
move of the game.

In a well-played game, there will typically be no double-crossed moves
until a loony endgame is reached, and there will be enough very long
chains and loops that whoever can gain control and make the last move
will win. If that happens, the player who gains control will play a
double-dealing move on each long chain or loop except the last one,
which means there will be one double-crossed move per long chain and
two double-crossed moves per long loop, except for the last turn of
the game, where there will be no double-crossed moves if it is a chain
being taken, and one if it is a loop.

This in turn means that if the number of long chains $L$ is
\emph{odd}, the number of double-crossed moves will be \emph{even},
and vice versa. (The number of long \emph{loops}, interestingly, is
irrelevant.)

Theorem \ref{gamelength} then tells us that if we started with $S$
strings and $C$ coins and $S-C+L$ is \emph{odd}, the total number of
turns in the game will be \emph{odd}, whereas if $S-C+L$ is
\emph{even}, the total number of turns will also be \emph{even}. This
gives us the following rule of thumb.

\begin{parityruleofthumb}\label{parityruleofthumb}
  If player $A$ plays the odd-numbered turns in a game starting with
  $S$ strings and $C$ coins, and player $B$ the even-numbered turns,
  both players should try to reach an endgame position with a number
  of long chains $L$ of a certain parity. Player $A$ will try to
  control $L$ so as to make $S-C+L$ \emph{odd}, whereas $B$ will try
  to make $S-C+L$ \emph{even}.
\end{parityruleofthumb}

The equivalent result for dots-and-boxes is as follows.

\begin{dnbparityruleofthumb}\label{dnbparityruleofthumb}
  In a dots-and-boxes game played on a board with $T$ dots, both
  players should try to reach an endgame position with a number of
  long chains $L$ of a certain parity. Player $A$ will try to make
  $T+L$ \emph{even}, whereas player $B$ will try to make it
  \emph{odd}.

  (Most dots-and-boxes games are played on a grid with an odd number
  of boxes, in which case $T$ is even and so player $A$ should try to
  aim for an even number of long chains, while player $B$ should try
  to aim for an odd number.)
\end{dnbparityruleofthumb}

These rules will work provided (a) there are sufficient very long
chains that making the last move is enough to guarantee winning the
game, and (b) the pattern of double-crossed moves does not deviate
from that described above (which normally only happens in expert play
when one player realises they are losing and tries to sacrifice some
boxes to confuse their opponent).

\subsection{Examples}

We now examine a couple of examples of these rules in operation, taken
from the exercises in \cite{berl}.

In Figure \ref{ex3p1}, we see a $3 \times 3$ dots-and-boxes position
with 10 moves having been made, and no captures, so player $A$ is to
move. The position has been divided into two structures, one to the
top and left (which is clearly going to become a long chain) and one
in the bottom right, which could become either a chain or a loop. By
Rule \ref{dnbparityruleofthumb}, player $A$ is aiming for an
\emph{even} number of long chains, so the correct move is to play the
highlighted move to turn the bottom right structure into a long
chain. Any other move loses, as $B$ will respond by taking any coins
on offer and then playing one of the ground strings in the bottom
right. It is worth playing the position through a few times to confirm
this.

\begin{figure*}
  \centering
  \def\svgscale{0.7}
  \input{fig_ex3p1.pdf_tex}
  \caption{Exercise 3.1 from \cite{berl}: $A$ to move, solution highlighted}
  \label{ex3p1}
\end{figure*}

In Figure \ref{ex3p12}, we see a more complex case: a $5 \times 5$
dots-and-boxes position with 28 moves having been made, and no
captures, so again player $A$ is to move. The only part of the
position which has not been resolved into a chain or a loop is the
four coins in the top right, so we immediately suspect a need to move
in this area --- but should we make it into a chain or a loop?

\begin{figure*}
  \centering
  \def\svgscale{0.7}
  \input{fig_ex3p12.pdf_tex}
  \caption{Exercise 3.12 from \cite{berl}: $A$ to move, solution highlighted}
  \label{ex3p12}
\end{figure*}

To answer that question, we must count the chains in the rest of the
position. This is slightly trickier than the previous case, because
most of the coins are joined together into a single mass, containing
two joints: the second coin of the first row, and the second coin of
the fourth row. However, once we see the joints, it is clear that
there are three long chains: one extending down and to the left from
the first joint, one extending right and down from the second joint,
and one connecting the two joints.

Since $A$ wants an even number of long chains, the correct move is to
turn the top right into a chain as indicated; other moves lose,
because $B$ would take any coins on offer and then take one of the
ground strings in the top right, turning it into a loop.

It should be clear that the chain-parity rules discussed in this
section are enormously helpful in analysing these late-middlegame
positions. Figure \ref{ex3p12}, in particular, would be very
time-consuming to analyse by brute force. Julian West's analysis of
some expert-level dots-and-boxes games in \cite{nochance} makes
repeated reference to these rules, and understanding how to apply them
is a vital step in the development of anyone who wants to improve
their skills at this game.

\subsection{$3 \times 3$ dots-and-boxes}

In \cite{berl}, Berlekamp gives a winning strategy for player $B$ in
$3 \times 3$ dots-and-boxes. By Rule \ref{dnbparityruleofthumb}, $B$
is aiming for an odd number of long chains; the idea is to force a
single long chain passing through the centre square by making the
moves shown in the pattern in Figure \ref{3by3strategy} (or its mirror
image).

\begin{figure*}
  \centering
  \def\svgscale{0.7}
  \input{fig_3by3strategy.pdf_tex}
  \caption{Player $B$'s winning strategy in $3 \times 3$ dots-and-boxes}
  \label{3by3strategy}
\end{figure*}

A sample game played according to this strategy may be found in Figure
\ref{3by3samplegame}.

\begin{figure*}
  \centering
  \def\svgscale{0.5}
  \input{fig_3by3samplegame.pdf_tex}
  \caption{Sample $3 \times 3$ game played according to Berlekamp's
    strategy}
  \label{3by3samplegame}
\end{figure*}

The end of the game is not shown, but it is clear that $A$ has been
forced to open the long chain of five boxes at the bottom, and that
$B$ will thus win 6--3. Particularly noteworthy is the sacrifice of
the middle right box by $B$ at the eighth move; this is done in order
to prevent the bottom right being turned into a loop. The sixth move
is also essential in order to prevent the top row being turned into a
second long chain. With those moves in place, the outcome of the game
is secured by basic endgame technique.

\section{Nimstring and Combinatorial Game Theory}

\subsection{Introduction}

Chain counting, as described in the previous section, is a powerful
technique for assessing middlegame positions. However, it is not
sufficient on its own when the position consists of multiple areas
where the number of long chains is not yet resolved.

For example, if there are two such areas, it may be undesirable to
make a move which resolves the chain count in either area, as our
opponent might then be able to resolve the count in the other area in
her favour. In other situations with multiple unresolved regions,
there may be a winning move available, but it might be quite difficult
to work out what it is.

For example, consider Figure \ref{nimstringmotivation} (taken from
\cite{berl}, p.\ 50). Here the top of the board is going to become a
single long chain; however, the two areas at the bottom are
unresolved. Fifteen moves have been made, so player $B$ is to move,
and she has a winning move here --- however, with only the techniques
we have learned so far, it is not easy to find.

\begin{figure*}
  \centering
  \def\svgscale{0.7}
  \input{fig_nimstringmotivation.pdf_tex}
  \caption{A $4 \times 5$ dots-and-boxes position with two
    unresolved regions}
  \label{nimstringmotivation}
\end{figure*}

All games of dots-and-boxes end up with the position being split into
multiple separate regions, as in Figure \ref{nimstringmotivation} ---
or at least, the players must consider the possibility of such splits
at many points during the game. What we would ideally like is a way of
analysing the separate parts of split positions independently, and
then combining those analyses together to assess the whole position
and choose the best move.

To find such a method, we will take a step back, and look at
strings-and-coins in the context of a broader mathematical theory of
games of this type. This is called Combinatorial Game Theory,
or CGT, and there is a very large and rich mathematical literature on
it.

The theory was founded in the early twentieth century, with the study
of games such as Nim (which we will meet soon). However, the key
founding text of modern CGT, which took the study of games to a
completely new level, is John Conway's book \cite{onag}, originally
published in the 1970s. \cite{wways} was also an important early
contribution. Today, the best introductory survey I am aware of is
Richard Guy's papers in \cite{nochance}; \cite{lip} is also an
excellent student-friendly textbook.

CGT focuses on games which:

\begin{enumerate}
  \item have two players, often called Left and Right, or $L$ and $R$,
    who move alternately;
  \item have (at most) two possible types of outcome: $L$ wins and $R$
    loses, or $R$ wins and $L$ loses (there are extensions to CGT
    which cover games which can be drawn or tied);
  \item are games of complete information, so both players know
    exactly what the game state is at all times;
  \item have no element of chance, so the possible moves from any
    position are always known deterministically, and there are no dice
    rolls, coin flips, or other random factors influencing the
    outcome; and
  \item are governed by the \emph{normal play convention}, where a
    player loses if, and only if, they have no legal options available
    when required to move.
\end{enumerate}

Many popular games satisfy the first four conditions (particularly if
draws are allowed), such as chess, draughts, go, and
strings-and-coins. Games which satisfy the normal play convention are
somewhat rarer: for example in chess, a player unable to move does not
necessarily lose (as stalemate is a draw).

Strings-and-coins also does not follow this convention, as the winner
is whichever player has captured most coins during the game, which is
not necessarily the player who captured the final coin.

However, CGT can often be helpful even for analysing games which do
not follow the normal play convention: for example, \cite{nochance}
shows some applications to chess and go, and \cite{wways} contains
many interesting examples also. We should not be surprised that CGT
can give useful insights about strings-and-coins, given how often the
game does in fact boil down to which player can control who makes the
last move.

In this section, we will study a new game called
\emph{Nimstring}. Nimstring is identical to strings-and-coins in every
way except one: the winner is not the player who takes more coins but
the player who forces his opponent to take the \emph{last}
coin. Nimstring satisfies all the conditions above (it is a
normal-play game because whoever takes the last coin is required to
play another move, but cannot) and is therefore ideally suited to
analysis using CGT.

Nimstring is actually a subset of strings-and-coins: any Nimstring
position $G$ can be converted to a strings-and-coins position simply
by adding a single long chain containing more coins than $G$. The
winner of this strings-and-coins game will be whichever player can win
the long chain, which will be precisely the player who can force his
opponent to capture the last coin in $G$.

There are a great many other strings-and-coins positions which can
also be won using Nimstring techniques. This should not be surprising,
as the ability to force your opponent to take the last coin in
Nimstring is virtually identical to the concept of control in
strings-and-coins which we have examined in earlier sections.

Now, we will first introduce the basic concepts and principles of CGT,
with a strong focus on laying the foundations for Nimstring. We will
then discuss that game in the context of what we have learned. Readers
interested in going into general CGT in more depth (an exercise well
worth doing) should consult the bibliography.

\subsection{Fundamentals of Combinatorial Game Theory}

In CGT, the term \emph{game} is defined in a very abstract way: it is
simply two sets of options, one defining the choices available to $L$
if it is $L$'s move, and the other defining the choices available to
$R$ if it is $R$'s move.

Formally, a game $G$ is recursively defined as an ordered pair of sets
of games: $$G = \cgtgame{\{G^{L_1}, G^{L_2}, \ldots\}}{\{G^{R_1},
  G^{R_2}, \ldots\}}$$ where $G^{L_1}$ etc are the games which $L$ can
choose to move to if it is $L$'s move, and $G^{R_1}$ etc are the games
which $R$ can choose to move to if it is $R$'s move. These two sets of
options can be empty, finite or infinite.

To keep the notation compact, the inner braces are often omitted:
$$G = \cgtgame{G^{L_1}, G^{L_2}, \ldots}{G^{R_1}, G^{R_2}, \ldots}$$
and sometimes the options are written as sets, i.e. $$G =
\cgtgame{\mathcal{G}^L}{\mathcal{G}^R}$$ where $\mathcal{G}^L =
\{G^{L_1}, G^{L_2}, \ldots\}$ and similarly for $\mathcal{G}^R$.

The game $\cgtgame{}{}$, where neither player has any legal moves, is
called the \emph{zero game} and is often just written as $0$. So for
example, the game $\cgtgame{0}{}$ is the game where $L$ has one legal
move leading to the zero game and $R$ has no legal moves;
$\cgtgame{}{0}$ is the game where $R$ has one legal move leading to
the zero game and $L$ has no legal moves, etc.

It can be shown that any game must belong to one of four \emph{outcome
  classes}, assuming best play from both players:

\begin{itemize}
  \item A win for $L$, regardless of who moves first (example:
    $\cgtgame{0}{}$)
  \item A win for $R$, regardless of who moves first (example:
    $\cgtgame{}{0}$)
  \item A win for whichever player moves first (example:
    $\cgtgame{0}{0}$)
  \item A win for whichever player moves second (example: $0$)
\end{itemize}

The true power of CGT lies in its ability to combine two games
together to make a new game. The \emph{sum} of two games is defined as
a new game with both games ``played side-by-side'', where each move
consists of choosing one of the games and making a move in
it. Formally, if $G = \cgtgame{\mathcal{G}^L}{\mathcal{G}^R}$ and $H =
\cgtgame{\mathcal{H}^L}{\mathcal{H}^R}$, then the left options of
$G+H$ are $$\{G'+H : G' \in \mathcal{G}^L\} \cup \{G+H' : H' \in
\mathcal{H}^L\}$$ and the right options are $$\{G'+H : G' \in
\mathcal{G}^R\} \cup \{G+H' : H' \in \mathcal{H}^R\}$$ In each case,
the left part of the union is the set of options where the player
plays in $G$ (leaving $H$ untouched), and the right part is the set
where the player plays in $H$ (leaving $G$ untouched).

(It may initially appear strange to define a particular position as
being ``the same game'' regardless of which side is to move. After
all, it makes an enormous difference whose turn it is in a game: for
example, in chess, changing the side to move can often have a bigger
effect than adding or removing pawns or pieces. This concept of sums
of games explains why a game is defined this way: when two games are
added together, the moves of the two players in a given sub-game may
not actually alternate any more, as one side may play consecutive
moves in one sub-game while the other side plays consecutive moves in
the other.)

Further, the \emph{negative} of a game is defined as the game where
the options of $L$ and $R$ are (recursively) reversed, so if again $G
= \cgtgame{\mathcal{G}^L}{\mathcal{G}^R}$ then $$-G = \cgtgame{\{-G' :
  G' \in \mathcal{G}^R\}}{\{-G' : G' \in \mathcal{G}^L\}}$$

Once we can add two games and negate an individual game, we can very
easily subtract games as well: $$G - H = G + (-H)$$

The next step is to define a notion of \emph{equality} for games. The
zero game is a loss for whichever player is to move, which is to say a
win for the second player; all games $G$ where the second player can
force a win are defined to be equal to the zero game (and we write $G
= 0$). Then, we say two games $G$ and $H$ are equal (and write simply
$G = H$) if $G - H = 0$ in this sense.

So $\cgtgame{0}{} + \cgtgame{}{0} = 0$ even though the sets of options
of the left and right sides are not literally identical, because both
are wins for the second player. And of course, we then also have
$\cgtgame{0}{} = -\cgtgame{}{0}$.

It can be shown that if $G = H$, then $G$ and $H$ are always in the
same outcome class (e.g.\ if $G$ is always a win for $L$ then so is
$H$), and moreover, for all games $X$, $G+X$ and $H+X$ are also always
in the same outcome class (indeed $G+X = H+X$), so the two games have
exactly the same effect on the outcome class when added to any third
game.

We can already see that games are, in a certain sense, behaving like
numbers:

\begin{itemize}
  \item They can be identified as equal or unequal to each other.
  \item They can be added and subtracted.
  \item There is a zero game such that $G + 0 = 0 + G = G$ for all $G$.
  \item Addition obeys the same commutative and associative laws as
    numerical addition ($G+H = H+G$ and $G+(H+I)=(G+H)+I$ for all
    games).
  \item Every game $G$ has an inverse $-G$ such that $G + (-G) = 0$.
\end{itemize}

In the terminology of abstract algebra, games form a structure called
a \emph{commutative group} (when each game is considered as
interchangeable with other equal games). This group is extremely rich
and interesting: there are games which behave like the integers
($\cgtgame{0}{}$ is like $1$ and $\cgtgame{}{0}$ is like $-1$), and
there are even games which behave like arbitrary fractions! There are
also games which do not behave like numbers at all.

\subsection{Impartial games}

Thankfully, we can leave a full discussion of the group of games to
textbooks such as \cite{lip}, because we are only interested in
Nimstring, which belongs to a very special class of games, called the
\emph{impartial} games.

An impartial game $G$ is one where the same set of options is
available to both players, i.e.\ $G =
\cgtgame{\mathcal{G}^E}{\mathcal{G}^E}$ for some set $\mathcal{G}^E$
which itself contains only impartial games. (A game which is not
impartial is called a \emph{partizan} game. In a partizan game, the
options available to the two players in a partizan game are different;
for example, chess is a partizan game, because one player controls the
White pieces, and the other the Black.) Nimstring is an impartial
game, because either player can remove any string when it is his turn
to move.

Any impartial game must either be a win for the first player or the
second player: unlike a partizan game, the outcome classes ``always a
win for $L$'' and ``always a win for $R$'' are impossible, because the
options for the two players are always the same, so one player can
always ``steal'' the other's winning strategy if the players' roles
are reversed (remember the proof technique from Theorem
\ref{sstealing}).

The game of \emph{Nim} is central to the theory of impartial games,
for a reason we will see shortly. In Nim, a position consists of a
finite number of \emph{heaps} of ``beans''; the two players take it in
turns to select one of the heaps and remove any number of beans from
it (at least one, up to and including the whole heap). The winner
(under the normal play convention) is the player who takes the last
bean.

Clearly, any one-heap game of Nim is a win for the first player,
because she can just take all the beans immediately. Similarly, a game
of two equal heaps is a win for the second player, because whatever
move the first player makes, her opponent can simply copy it in the
other heap.

Nim is ideally suited for analysis using the concepts of CGT we saw in
the previous sub-section. A game of Nim with $n$ heaps behaves exactly
like the sum of $n$ separate one-heap games. From a single heap with
$n$ beans, both players have the same set of $n$ choices: they can
take any number of beans from $1$ up to $n$. We therefore use the
shorthand $*n$ for a single Nim-heap of size $n$; formally, $*n$ is
defined inductively as follows:

\begin{eqnarray*}
  *0 & = & 0 \\
  *(n+1) & = & \cgtgame{*0, *1, \ldots, *n}{*0, *1, \ldots, *n}
\end{eqnarray*}

In CGT, these games are referred to as \emph{nimbers}. All non-zero
nimbers are first-player wins, because the first player can always
move to the zero game. Also, all nimbers are self-inverse: $*n + *n =
0$ for all $n$, because a game of two equal heaps is a second-player
win as we saw above.

Nim was solved by the American mathematician Charles L.\ Bouton in
1901. Though the terminology of ``nimbers'' and other CGT concepts was
not invented until later, Bouton effectively showed that:

\begin{enumerate}
  \item The sum of any two nimbers is another nimber, so any Nim
    position behaves exactly like a single Nim-heap.
  \item For any nimbers $*m$ and $*n$, the way to find $*m + *n$ is to
    represent $m$ and $n$ as binary numbers and exclusive-or
    ($\oplus$) them together (or equivalently, add the two binary
    numbers together without performing any carrying).
  \item Any Nim position equal to $0$ is a win for the second player;
    all other Nim positions are a win for the first player.
  \item The winning strategy in any Nim position which is not equal to
    $0$ is to find and play a move to a $0$ position, which is always
    possible.
\end{enumerate}

(From our earlier discussion of CGT and the definition of nimbers, we
can see that the last two points are implied by the first two.)

Here are some examples of nimber addition:

\begin{itemize}
  \item $*1 + *2 = *3$, since $1 = 01_2$, $2 = 10_2$ and $01_2 \oplus
    10_2 = 11_2 = 3$
  \item $*1 + *3 = *2$ since $3 = 11_2$ and $01_2 \oplus 11_2 = 10_2 =
    2$
  \item $*2 + *7 = *5$ since $2 = 010_2$, $7 = 111_2$ and $010_2
    \oplus 111_2 = 101_2 = 5$.
\end{itemize}

As an example of the winning strategy for Nim, suppose we start with
three heaps, of 13, 23 and 28 counters. Now:

\begin{eqnarray*}
  13 & = & 01101_2 \\
  23 & = & 10111_2 \\
  28 & = & 11100_2 \\
  13 \oplus 23 \oplus 28 & = & 00110_2 = 6
\end{eqnarray*}

So the whole position is equal to $*6$ and one winning move would be
to take $6 = 00110_2$ coins from the 23-heap, since $*13 + *17 + *28 =
0$.

Now why, in a paper about dots-and-boxes, did we spend time studying
Nim, which appears on the surface to be a completely different game?
The answer is that in the 1930s, the German mathematician Roland
P.\ Sprague and the English mathematician Patrick M.\ Grundy
independently discovered that, crucially, \emph{any} impartial game
played according to the normal play convention\footnote{Surprisingly,
  if we reverse the normal play convention so that the last move
  loses, which is called \emph{mis\`ere play}, the situation is much
  more complicated.} is equal to a nimber. This means that any
normal-play impartial game whatsoever is equivalent to a single Nim
heap.

Specifically, the Sprague-Grundy Theorem states that if $$G =
\cgtgame{*a, *b, *c, \ldots}{*a, *b, *c, \ldots}$$ then $G = *n$
where $$n = \mex(a, b, c, \ldots)$$ where the function $\mex$ (short
for \emph{minimal excludant}) is defined as the smallest non-negative
integer which is not a member of $\{a, b, c, \ldots\}$.

For example:

\begin{eqnarray*}
  \mex() & = & 0 \\
  \mex(0, 1, 2) & = & 3 \\
  \mex(1, 2) & = & 0 \\
  \mex(0, 2, 3) & = & 1
\end{eqnarray*}

This is a remarkable result, because it shows that, in a certain very
important sense, all impartial games are actually the same ---
although there is no guarantee that it will be easy, in any given
case, to calculate the value of a position or find a winning move
(i.e.\ one which reaches a zero position).

The Sprague-Grundy Theorem shows why the name Nimstring was chosen for
our normal-play variant of strings-and-coins: like all impartial
games, Nimstring has a profound connection with Nim.

\subsection{Complimenting moves and loony values}

As with any impartial game, to calculate the value\footnote{When we
  talk about the \emph{value} of a Nimstring position, we mean the
  Sprague-Grundy value, which is not to be confused with the minimax
  coin-score value function $V$ we introduced for strings-and-coins
  earlier.} of any Nimstring position, all we need to do is to
recursively calculate the value of each option of that position, and
then calculate the $\mex$ of the results. For example, if the moves
from a given Nimstring position are to positions of value $*1$, $*2$,
$*2$ and $0$, then the position has value $\mex(1, 2, 2, 0) = *3$.

We can easily see that any Nimstring position where only loony moves
remain is a second-player win and thus has a value of $0$: we can see
that any loony Nimstring position is a first-player win by an argument
virtually identical to Theorem \ref{sstealing}. In fact, the analysis
for Nimstring is even simpler, because we do not have to worry about
numerical comparison of scores. Either the remainder of the position
is a first-player win (if it equals a non-zero nimber) or a
second-player win (if it equals zero), and a loony move gives us a
free choice of whether to move first or second.

The problem is that not all Nimstring positions can be evaluated so
easily. If done na\"ively, the computational cost of the calculation
grows exponentially in the size of the position, because we must do
one recursive computation for each option. It would make the
calculation much simpler if, as discussed in the introduction to this
section, we could separately calculate the values of the independent
components of a Nimstring position and cheaply combine them together
to reach the value of the position as a whole.

It might initially appear that Sprague-Grundy theory gives us exactly
what we are looking for. All we now need to do, one might think, is
calculate the nimber value of each separate component, and then use
nimber addition, just as we did for Nim.

Unfortunately, however, there is a serious problem. If $G$ and $H$ are
Nimstring positions (with at least one coin), there is a very
important difference between (a) playing a single Nimstring position
with $G$ and $H$ as independent components, and (b) playing the game
$G+H$. In Nimstring, if a player captures a coin in $G$, she can
continue with a move in $H$, which would mean that moves in both $G$
and $H$ have been made \emph{as part of the same turn}. In the game
$G+H$, this would not be allowed: each move in a sum game must be
confined to one of the components of the sum. This means that the
value of a combined Nimstring position is \emph{not}, in general,
equal to the nim-sum of its independent components.

For example, suppose $G$ is a loony position; then the combined
Nimstring position is also a loony position, and therefore a
first-player win (not equal to $0$) \emph{regardless} of the value of
$H$. There is no nimber $*g$ such that $*g + *h \neq 0$ for all $*h$
(since all nimbers are self-inverse, i.e.\ $*g + *g = 0$), so nimber
addition simply does not seem to behave the way we need it to. It
appears we are stuck with the exponential calculation for the full
position, and that breaking the position down into components does not
help.

In CGT, moves which allow the same player to play again are called
\emph{complimenting moves}. In Nimstring, capturing a coin is a
complimenting move.

Fortunately, it is possible to extend Sprague-Grundy theory to support
impartial games with complimenting moves, such as Nimstring. The
method comes from Chapter 12 in Volume 2 of \cite{wways}, but the
analysis there also supports other game features which Nimstring does
not have, so we do not need to introduce the full theory here.

For Nimstring, all we need is to introduce a new special game value,
$\loony$, for loony positions, with the following properties:

\begin{eqnarray*}
  \loony + *n & = & \loony \quad (\forall n)\\
  \loony + \loony & = & \loony \\
  \mex(a, b, \ldots, \loony) & = & \mex(a, b, \ldots)
\end{eqnarray*}

(The first two definitions are easily justified by our earlier
observation that a loony position is still a loony position regardless
of what other positions are added. The third comes from the fact that
in Nimstring, any loony move is a losing move, so when evaluating a
position, loony moves can be ignored: if only loony moves are
available, the first player is losing, so the value of the position is
$0 = \mex()$.)

We can then calculate the value of any Nimstring position as follows:

\begin{enumerate}
  \item The value of the empty position is $0$.
  \item The value of a position where a double-dealing move is
    possible is $\loony$.
  \item The value of a position where there are capturable coins but
    no available double-dealing moves is the same as the value of the
    position with those coins removed.
  \item The value of any other position is equal to the nim-sum of
    each of its options.
\end{enumerate}

The first two of these are clear.

The third can be seen by imagining such a position $G$ added to
another position $H$ identical to $G$ except with the capturable coins
removed. This is a zero game, because the first player must end with
some move available in both $G$ and $H$ (either with or without
capturing some of the coins in $G$ beforehand). If this is a loony
move, the first player has conceded defeat immediately; if not, the
second player can respond by capturing any of the originally
capturable coins in $G$ which still remain, followed by mirroring his
opponent's final move in the other component, resulting in two
identical non-loony components, which have total value $0$ since all
nimbers are self-inverse.

The fourth follows from the Sprague-Grundy Theorem for ``ordinary''
impartial games, plus our earlier observation that loony moves can be
ignored when evaluating a position.

We can easily see that addition in our extended value system still
obeys the commutative and associative laws, and thus we have an
essentially ``well-behaved'' theory.\footnote{Since $\loony$ has no
  inverse, technically our extended set of values is no longer a group
  but a commutative monoid, but that has no real significance.}

We now have the tools we need for understanding a Nimstring position
as (quite literally) the sum of its parts.

Figure \ref{nimstringexamples} shows some examples of Nimstring
positions with their values. In particular, note that any long chain
or loop has a value of $0$, because all options from it are loony, so
when calculating the value of a position, they can be ignored.

\begin{figure*}
  \centering
  \def\svgscale{0.7}
  \input{fig_nimstringexamples.pdf_tex}
  \caption{Examples of simple Nimstring values}
  \label{nimstringexamples}
\end{figure*}

\appendix

\section{Proof of Theorem \ref{gamelength}}\label{gamelengthproof}

We proceed by induction on $S$.

The base case is $S=1$. There are exactly two positions with a
single string:

\begin{itemize}
  \item a single coin connected to the ground, in which case $C=1$ and
    $D=0$ (since a double-crossed move requires at least two coins)
  \item a pair of connected coins with no connections to the ground,
    in which case $C=2$ and $D=1$ (since the only move available is
    a double-crossed move).
\end{itemize}

In both these cases, since there is only one string to remove, the
game will clearly consist of a single turn, and in both cases also
$1+S-C+D = 1$, so the base case is proved.

For the inductive step, we assume the result is true for an
arbitrary position $P$ with $s$ strings and $c$ coins, i.e.\ that any
game starting from $P$ with $d$ double-crossed moves will have
$1+s-c+d$ turns. We are required to show that if we add one string
to $P$, the result still holds for the resulting position $P'$ with
$s+1$ strings.

To do this, we consider an arbitrary game starting from $P'$. We
imagine making the same sequence of moves (excluding the new string)
starting from $P$, and examine the relationship between the number
of turns in the two games. We will call the two games ``the $P'$
game'' and ``the $P$ game'' for short.

The only ways of adding one string to a strings-and-coins position
are as follows:

\begin{enumerate}
  \item Adding a new independent component with a single string
  \item Adding a new string connecting an existing coin to the
    ground
  \item Adding a new coin connected to an existing coin
  \item Adding a new string connecting two existing coins
\end{enumerate}

We need to consider each of these.

The first case is quite straightforward. There are only two possible
one-string components we can add: the same two we examined above in
the base case. Neither one affects the total number of turns in the
game: taking the new string will capture at least one coin and thus
will not pass control to the other player, and nor will it have any
effect on the rest of the position. The $P'$ and $P$ games will thus
have exactly the same number of turns.

Adding a single new coin connected to the ground increases both $S$
and $C$ by 1 but cannot affect $D$; adding a pair of new coins
connected together increases $S$ and $D$ by 1 and $C$ by 2. Both
additions therefore leave the quantity $1+S-C+D$ unchanged, as
required. This is summarised in Table \ref{gamelengthcase1}.

\begin{table*}[p]
  \centering
  \begin{tabular}{c c c c c}
    New component & $\Delta S$ & $\Delta C$ & $\Delta D$ & $\Delta$
    turns \\
    \hline
    Single coin connected to ground & $+1$ & $+1$ & 0 & 0 \\
    Pair of connected coins & $+1$ & $+2$ & $+1$ & 0
  \end{tabular}
  \caption{New independent component with a single string}
  \label{gamelengthcase1}
\end{table*}

The other cases require a little more care, because depending on the
circumstances, they might or might not affect $D$ and the number of
turns.

Consider the second case, where we add a new string connecting an
existing coin, which we will call $\alpha$, to the ground. If removing
this new string does \emph{not} capture $\alpha$ in the $P'$ game,
then that move will pass control to the other player, and each
subsequent move will be made by the opposite player to its equivalent
in the $P$ game. The $P'$ game thus has one more turn, but the same
number of double-crossed moves (as taking a ground string cannot be a
double-crossed move), which is exactly what the theorem requires, as
$S$ has increased by 1 but the other quantities have stayed the same.

Suppose alternatively that removing the new string \emph{does} capture
$\alpha$ (which will not be a double-crossed move, as removing a
string connected to the ground never is). Then the difference between
the two games depends on whether the capture of $\alpha$ in the $P$
game is a double-crossed move. If so, then the same move in the $P'$
game will still be a capture, but not a double-crossed move, and so
$D$ is 1 less than in the $P$ game, but the number of turns is the
same. On the other hand, if the capture of $\alpha$ in the $P$ game is
\emph{not} a double-crossed move, then the same move in the $P'$ game
will not be a capture at all, and hence will pass control to the
opponent, which it does not do in the $P$ game, in which case the two
games have the same number of double-crossed moves, but the $P'$ game
has one more turn.

Both these cases satisfy the requirements of the theorem: in one case
$S$ increases, $D$ decreases and the number of turns stays the same,
and in the other, $S$ increases, $D$ stays the same, and the number of
turns increases. These sub-cases are summarised in Table
\ref{gamelengthcase2}.

\begin{table*}[p]
  \centering
  \begin{tabular}{c c c c c c}
    $\sigma$ caps.\ $\alpha$ in $P'$ game & Cap.\ of $\alpha$
    in $P$ game is d-c & $\Delta S$ & $\Delta C$ & $\Delta D$ &
    $\Delta$ turns \\
    \hline
    No & Either & $+1$ & 0 & 0 & $+1$ \\
    Yes & No & $+1$ & 0 & 0 & $+1$ \\
    Yes & Yes & $+1$ & 0 & $-1$ & 0
  \end{tabular}
  \caption{New string $\sigma$ connecting existing coin $\alpha$ to
    the ground}
  \label{gamelengthcase2}
\end{table*}

Now we move on to the third case, where we add a new coin $\alpha$ to
$P$, connected to an existing coin which we will call $\beta$.

In this case, the first key question is whether the capture of
$\alpha$ in the $P'$ game is a double-crossed move. If not, the $P$
and $P'$ games have the same number of turns and the same number of
double-crossed moves, as the capture of $\beta$ in the $P'$ game is a
double-crossed move if and only if it also is in the $P$ game.

If the capture of $\alpha$ in the $P'$ game \emph{is} a double-crossed
move, then we need to know whether the capture of $\beta$ is a
double-crossed move in the $P$ game. If so, then the same move in the
$P'$ game is a capture but not a double-crossed move, so there is no
net change in the number of double-crossed moves or the number of
turns. If not, then the equivalent move in the $P'$ game is not a
capture at all, so we have an extra double-crossed move in the $P'$
game as well as an extra turn.

All three sub-cases satisfy the requirements of the theorem: there is
no change in the quantity $1+S-C$, and we either have the same number
of turns and the same number of double-crossed moves, or one extra
double-crossed move and one extra turn. This is summarised in Table
\ref{gamelengthcase3}.

\begin{table*}[p]
  \centering
  \begin{tabular}{c c c c c c}
    $\sigma$ in $P'$ game is d-c & Cap.\ of $\beta$ in $P$
    game is d-c & $\Delta S$ & $\Delta C$ & $\Delta D$ & $\Delta$
    turns \\
    \hline
    No & Either & $+1$ & $+1$ & 0 & 0 \\
    Yes & No & $+1$ & $+1$ & $+1$ & $+1$ \\
    Yes & Yes & $+1$ & $+1$ & 0 & 0
  \end{tabular}
  \caption{New coin $\alpha$ connected to existing coin $\beta$ by new
  string $\sigma$}
  \label{gamelengthcase3}
\end{table*}

Finally, we turn our attention to the fourth case, where we add a new
string between two existing coins, $\alpha$ and $\beta$.

First, we ask whether removing this string is a capture in the $P'$
game. If not, the two games have the same number of double-crossed
moves, but the $P'$ game has an extra turn.

Otherwise, we ask whether this move in the $P'$ game is a
double-crossed move. If not, it captures exactly one of $\alpha$ or
$\beta$, and we have the same situation as in case 2 where removing
the new string is a capture in the $P'$ game: we either have one fewer
double-crossed move and the same number of turns, or the same number
of double-crossed moves and one more turn.

If the new string in the $P'$ game is a double-crossed move, the
outcome depends on whether the captures of $\alpha$ and $\beta$ in the
$P$ game are double-crossed moves. Both, one and neither are all
possibilities.

\begin{itemize}
\item If both, we have replaced two double-crossed moves with one,
  with no change in the number of turns (as the relevant moves are all
  captures).
\item If one (without loss of generality we can let it be $\alpha$),
  we have not changed the number of double-crossed moves, but we have
  added a turn, as the capture of $\beta$ in the $P$ game is not a
  capture at all in the $P'$ game.
\item If neither, we have added one double-crossed move, and we have
  added \emph{two} turns to the game, as neither of the captures of
  $\alpha$ and $\beta$ in the $P$ game are captures at all in the $P'$
  game.
\end{itemize}

In all three cases, we have met the requirements of the theorem, as
the change in the number of turns is the same as the change in
$1+S-C+D$. These sub-cases are summarised in Table
\ref{gamelengthcase4}.

\begin{table*}[p]
  \centering
  \begin{tabular}{c c c c c c c}
    $\sigma$ cap.\ in $P'$ game & $\sigma$ d-c in $P'$ game &
    Caps.\ of $\sigma$ in $P'$ d-c in $P$ & $\Delta S$ & $\Delta
    C$ & $\Delta D$ & $\Delta$ turns \\
    \hline
    No & No & N/A & $+1$ & 0 & 0 & $+1$ \\
    Yes & No & No & $+1$ & 0 & 0 & $+1$ \\
    Yes & No & Yes & $+1$ & 0 & $-1$ & 0 \\
    Yes & Yes & Neither & $+1$ & 0 & $+1$ & $+2$ \\
    Yes & Yes & One & $+1$ & 0 & 0 & $+1$ \\
    Yes & Yes & Both & $+1$ & 0 & $-1$ & 0
  \end{tabular}
  \caption{New string $\sigma$ connecting existing coins $\alpha$
    and $\beta$}
  \label{gamelengthcase4}
\end{table*}

There are no remaining cases, and thus the proof is complete.

\section{A note on sources}

This paper was the product of some difficulties I experienced with
existing sources on dots-and-boxes.

\cite{berl} is the only major work I know of focusing solely on the
game. It contains many important results and useful exercises, and
this paper would have been impossible without it, but it does not give
proofs for many key assertions, or go into as much depth as I would
have liked. This paper started as an attempt to prove some of the
results in that book, and to understand its contents more deeply
through my own analysis.

\cite{wways} contains a chapter on dots-and-boxes which has a
considerable overlap with \cite{berl} (even containing some identical
illustrations and formulations). While it does contain some valuable
non-overlapping material, I find the work as a whole, while it
contains much material of great interest, has many of the same
structural and stylistic problems as that book.

\cite{nochance} contains many excellent essays on Combinatorial Game
Theory, but has only a very cursory treatment of dots-and-boxes (a
single paper analysing a couple of games played by experts).

\cite{lip} is an excellent textbook on Combinatorial Game Theory which
I became aware of only recently. It has some material on
dots-and-boxes, but its focus is on the mathematics rather than one
specific game. (It also has the virtue, alone among these sources at
the time of writing, of being available on Amazon Kindle!)

\begin{thebibliography}{99}
  \bibitem{berl} Elwyn R.\ Berlekamp, \emph{The Dots-and-Boxes Game},
    A~K~Peters 2000
  \bibitem{wways} Elwyn R.\ Berkelamp, John H.\ Conway, Richard
    K.\ Guy, \emph{Winning Ways for Your Mathematical Plays},
    A~K~Peters 2003 (dots-and-boxes is discussed in Volume 3, Chapter
    16)
  \bibitem{nochance} Richard J.\ Nowakowski ed., \emph{Games of No
    Chance}, Cambridge University Press 1998
  \bibitem{onag} John H.\ Conway, \emph{On Numbers and Games},
    A~K~Peters 2000
  \bibitem{lip} Michael H.\ Albert, Richard J.\ Nowakowski, David
    Wolfe, \emph{Lessons in Play: An Introduction to Combinatorial
      Game Theory}, A~K~Peters 2007
\end{thebibliography}

\section*{Copyright notice}

This paper is Copyright 2016 Andrew Medworth, and is licensed under a
Creative Commons Attribution-NonCommercial-ShareAlike 4.0
International
License\footnote{\texttt{http://creativecommons.org/licenses/by-nc-sa/4.0/}}.

\input{vc.tex} The original source of this paper is a Git
repository\footnote{\texttt{https://github.com/amdw/dotsandboxes}},
and this version was generated from commit \VCRevisionMod.

\end{document}
